{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc310a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type constraints\n",
    "Datatype              Example                                Python data type\n",
    "Text data             First name, last name, address, ...    str\n",
    "Integers              # Subscribers, # products sold, ...    int\n",
    "Decimals              Temperature, $ exchange rates, ...     float\n",
    "Binary                Is married, new customer, yes/no, ...  bool\n",
    "Dates                 Order dates, ship dates, ...           datetime\n",
    "Categories            Marriage status, gender ...            category\n",
    "\n",
    "# Strings to integers\n",
    "# Import CSV file and output header\n",
    "sales = pd.read_csv('sales.csv')\n",
    "sales.head()\n",
    "    #prints below output\n",
    "    SalesOrderID    Revenue    Quantity\n",
    "0   43659           23153$     12\n",
    "1   43660           1457$      2\n",
    "\n",
    "# Set data types of columns\n",
    "sales.dtypes\n",
    "    #prints below output\n",
    "SalesOrderID    int64\n",
    "Revenue         object\n",
    "Quantity        int64\n",
    "dtype: object\n",
    "\n",
    "# Get dataframe information\n",
    "sales.info()\n",
    "    #prints below output\n",
    "<class 'pandas.core.frame.DataFrame'> \n",
    "RangeIndex: 31465 entries, 0 to 31464 \n",
    "Data columns (total 3 columns):\n",
    "SalesOrderID    31465 non-null int64\n",
    "Revenue         31465 non-null object\n",
    "Quantity        31465 non-null int64\n",
    "dtypes: int64(2), object(1)\n",
    "memory usage: 737.5+ KB\n",
    "\n",
    "# print sum of all Revenue column \n",
    "sales['Revenue'].sum()  # prints '23153$1457$36865$32474$472$27510$16158$5694$6876$40487$807$6893$9153$6895$4216..\n",
    "\n",
    "# Remove $ from Revenue column\n",
    "sales['Revenue'] = sales['Revenue'].str.strip('$')\n",
    "sales['REvenue'] = sales['Revenue'].astype('int')\n",
    "\n",
    "# Verify that Revenue is now an integer\n",
    "assert sales['Revenue'].dtype == 'int' #prints nothing if the condition is met\n",
    "\n",
    "# This will not pass\n",
    "assert 1+1 == 3 \n",
    "#prints\n",
    "AssertionError                   Traceback (most recent call last)\n",
    "        assert 1+1 == 3\n",
    "AssertionError:\n",
    "    \n",
    "\n",
    "# Numeric or categorical?\n",
    "marriage_status(column) - values(3, 1, 2)\n",
    "0 = Never married, 1 = Married, 2 = Separated, 3 Divorced\n",
    "\n",
    "df['marriage_status'].describe() #prints (marriage_status - mean 1.4, std 0.20, min 0.00, 50% 1.8 ...)\n",
    "\n",
    "#convert to catogorical\n",
    "df['marriage_status'] = df['marriage_status'].astype('category') \n",
    "df['marriage_status'].describe() #prints (marriage_status - count 241, unique 4, top 1, freq 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data range constraints\n",
    "How to deal with out of range data?\n",
    "• Dropping data\n",
    "• Setting custom minimums and maximums\n",
    "• Treat as missing and impute\n",
    "• Setting custom value depending on business assumptions\n",
    "\n",
    "# Movie example (when avg_rating should be 1-5 but has values out of range >5 in dataframe)\n",
    "import pandas as pd\n",
    "\n",
    "# output Movies with rating > 5\n",
    "movies[movies['avg_ratiing'] > 5]\n",
    "\n",
    "# Drop values using filtering\n",
    "movies = movies[movies['avg_rating'] <= 5]\n",
    "\n",
    "# Drop values using .drop()\n",
    "movies.drop(movies[movies['avg_rating'] > 5].index, inplace=True)\n",
    "\n",
    "# Assert the results\n",
    "assert movies['avg_rating'].max() <= 5\n",
    "\n",
    "# Convert avg_rating > 5 to 5\n",
    "movies.loc[movies['avg_rating'] > 5, 'avg_rating'] = 5\n",
    "\n",
    "\n",
    "# Subscriptions example(when subcription dates have future dates which should be < dt.date.today())\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "# Convert to date type\n",
    "user_signups['subscription_date'] = pd.to_datetime(user_signups['subscription_date']).dt.date\n",
    "\n",
    "today_date = dt.date.today()\n",
    "\n",
    "# Drop the data\n",
    "# Drop values using filtering\n",
    "user_signups = user_signups[user_signups['subscription_date'] < today_date]\n",
    "# Drop values using .drop()\n",
    "user_signups.drop(user_signups[user_signups['subscription_date'] < today_date].index, inplace=True)\n",
    "\n",
    "# Hardcode dates with upper limit\n",
    "# Drop values using filtering\n",
    "user_signups.loc[user_signups['subscription_date'] < today_date, 'subscription_date'] = today_date\n",
    "#Assert is True\n",
    "assert user_signups.subscription_date.max().date() <= today_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02374d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniqueness constraints\n",
    "What are duplicate values?\n",
    "Most columns have the same values\n",
    "first_name last_name  address                                    height weight\n",
    "Justin     Saddlemyer Boulevard du Jardin Botanique 3, Bruxelles 193 cm 87 kg\n",
    "Justin     Saddlemyer Boulevard du Jardin Botanique 3, Bruxelles 194 cm 87 kg #only diff in height column\n",
    "\n",
    "# Why do they happen\n",
    "Data entry & Human error\n",
    "Join or merge errors\n",
    "bugs and design errors\n",
    "\n",
    "How to find duplicate rows?\n",
    "The .duplicated() method\n",
    "subset : List of column names to check for duplication.\n",
    "keep: Whether to keep first ('first'), last ('Last') or all (False) duplicate values.\n",
    "    \n",
    "# Get duplicate roes across all columns\n",
    "duplicates = height_weight.duplicated()\n",
    "print(duplicates) #Returns True for duplicated values and False for non duplicated values\n",
    "\n",
    "# column names to check for duplication\n",
    "column_names = ['first_name', 'last_name', 'address']\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "\n",
    "# output duplicate values\n",
    "height_weight[duplicated].sort_values(by = 'first_name') #returns all complete and incomplete duplicates\n",
    "\n",
    "How to treat duplicate values?\n",
    "The .drop_duplicates () method\n",
    "subset : List of column names to check for duplication.\n",
    "keep: Whether to keep first ('first'), last ('last') or all (False) duplicate values.\n",
    "inplace: Drop duplicated rows directly inside DataFrame without creating new object (True).\n",
    "    \n",
    "# Drop duplicates\n",
    "height_weight.drop_duplicates(inplace = True) # dropes complete duplicates\n",
    "\n",
    "# how to treat incomplete duplicates #use .groupby() and .agg() methods\n",
    "# Group by column names and produce statistical summaries\n",
    "column_names = ['first_name', 'last_name', 'address']\n",
    "summaries = {'height': 'max', 'weight':'mean'} # takes max value in height and mean of weights among each duplicate\n",
    "height_weight = height_weight.groupby(by = column_names).agg(summaries).reset_index()\n",
    "\n",
    "# Make sure aggregation is done\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep=False)\n",
    "height_weight[duplicates].sort_values(by = 'first_name') # returns empty if duplicates are cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text and categorical data problems\n",
    "# Categories and membership constraints\n",
    "# Predefined finite set of categories\n",
    "Type of data                Example values           Numeric representation\n",
    "Marriage Status             unmarried, married       0,1                     #Marriage status can only be unmarried _or_ married\n",
    "Household Income Category   0-20K, 20-40K, ...       0,1,..\n",
    "Loan Status                 default, payed, no_Loan  0,1,2\n",
    "\n",
    "# Some of the datasets can have out of range values\n",
    "\n",
    "# How do we treat these problems?\n",
    "Dropping Data\n",
    "Remapping Categories\n",
    "Inferring Categories\n",
    "\n",
    "# Finding inconsistent categories\n",
    "inconsistent_categories = set(study_data['blood_type']).difference(categories['blood_type'])\n",
    "print(inconsistent_categories) # prints out of range values such as z+ in blood types\n",
    "\n",
    "# Get and print rows with inconsistent categories\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistent_categories)\n",
    "study_data[inconsistent_rows] # prints complete rows with out of range values\n",
    "\n",
    "# Dropping inconsistent categories\n",
    "inconsistent_data = study_data[inconsistent_rows]\n",
    "consistent_data = study_data[~inconsistent_rows]\n",
    "\n",
    "\n",
    "# What type of errors could we have?\n",
    "I) Value inconsistency\n",
    "    • Inconsistent fields: 'married', 'Maried', 'UNMARRIED' 'not married' ..\n",
    "    • Trailing white spaces: _ 'married ' 'married\n",
    "II) Collapsing too many categories to few\n",
    "    • Creating new groups: 0-20K, 20-40K categories ... from continuous household income data\n",
    "    • Mapping groups to new ones: Mapping household income categories to 2 'rich', 'poor' \n",
    "III) Making sure data is of type category (seen in Chapter 1)\n",
    "\n",
    "# Value consistency\n",
    "Capitalization: 'married', 'Married', 'UNMARRIED' 'unmarried'\n",
    "# capitalize\n",
    "marriage_status['marriage_status'] = marriage_status['marriage_status'].str.upper()  #all values are turned in uppercase\n",
    "# lowercase\n",
    "marriage_status['marriage_status'] = marriage_status['marriage_status'].str.lower()  #all values are turned in lowercase\n",
    "\n",
    "Trailing spaces: 'married ', 'married', 'unmarried',' Unmarried',\n",
    "# strip all spaces\n",
    "demographics = demographics['marriage_status'].str.strip() # removes white spaces in beggining and end\n",
    "\n",
    "\n",
    "# collapsing data into categories\n",
    "# Using cut() - create category ranges and names\n",
    "ranges = [0, 200000, 500000, np.inf]\n",
    "group_names = ['0-200k', '200k-500k', '500k+']\n",
    "# Create income group column\n",
    "demographics['income_group'] = pd.cut(demographocs['household_income'], bins=ranges, labels=group_names)\n",
    "demographics[['income_group', 'household_income']] # outputs 0-200k for 188923 and 500k+ for 778533 in a category column\n",
    "\n",
    "# Collapsing data into categories\n",
    "Map categories to fewer ones: reducing categories in categorical column.\n",
    "operating system column is: 'Microsoft', 'MacOS', 'IOS', 'Android', 'Linux'\n",
    "operating system column should become: 'DesktopOS', 'MobileOS'\n",
    "    \n",
    "# creating mapping dictionary and replace\n",
    "mapping = {'Microsoft':'DesktopOS', 'MacOS':'DesktopOS', 'Linux':'DesktopOS', 'IOS':'MobileOS', 'Android':'MobileOS'}\n",
    "\n",
    "devices['operating_system'] = devices['operating_system'].replace(mapping)\n",
    "devices['operating_system'].unique() # prints array(['DesktopOS', 'MobileOS'], dtype=object)\n",
    "\n",
    "# Common text data problems\n",
    "1) Data inconsistency:\n",
    "+96171679912 or 0096171679912 or ..?\n",
    "2) Fixed length violations:\n",
    "Passwords needs to be at least 8 characters\n",
    "3) Typos:\n",
    "+961.71.679912\n",
    "\n",
    "Name                Phone_number\n",
    "Gil B. Silva        001-195-492-2338\n",
    "Prescott D. Hardin   +1-297-996-4904    <-- Inconsistent data format\n",
    "Benedict G. Valdez  001-969-820-3536\n",
    "Reece M. Andrews                4138    <-- Length violation\n",
    "\n",
    "# Fixing the phone number column\n",
    "phones['Phone_number'] = phones['phone_number'].str.replace('+','00') #replace + with 00\n",
    "\n",
    "# Replace phone numbers with lower than 10 digits to NaN\n",
    "digits = phones['Phone_number'].str.len()\n",
    "phones.loc[digits < 10, 'Phone_number'] = np.nan\n",
    "phones # prints NaN where digits are < 10\n",
    "\n",
    "# Assert min phone number length is 10\n",
    "assert digits.min() >= 10\n",
    "\n",
    "# Assert all numbers do not have \"+\" or \"-\"\n",
    "assert phones['Phone_number'].str.contains('+|-').any() == False\n",
    "\n",
    "# Replace letters with nothing\n",
    "phones['Phone_number'] = phones['Phone_number'].str.replace(r'\\D+', '') # replaces anything that is not digit with nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca146d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advance data problems\n",
    "# Uniformity\n",
    "Column         Unit\n",
    "Temperature    32°C is also 89.6°F\n",
    "Weight         70 Kg is also 11 st.\n",
    "Date           26-11-2019 is also 26, November, 2019\n",
    "Money          100$ is also 10763.90¥\n",
    "\n",
    "Date        Temperature\n",
    "06.03.19    16.0\n",
    "07.03.19    62.6  <-- #this can be fahrenheit (can be known by plotting)\n",
    "\n",
    "c = (F - 32) * 5/9 #Formula to convert fahrenheit to celsius\n",
    "\n",
    "temp_fah = temperatures.loc[temperatures['Temperature'] > 40, 'Temperature']\n",
    "temp_cels = (temp_fah - 32) * 5/9\n",
    "temperatures.loc[temperatures['Temperatures'] > 40, 'Temperatures'] = temp_cels\n",
    "\n",
    "# Assert conversion is correct\n",
    "assert temperatures['Temperature'].max() < 40\n",
    "\n",
    "\n",
    "# Treating date data\n",
    "Birthday          First name   Last name\n",
    "27/27/19          Rowan        Nunez       ??\n",
    "03-29-19          Brynn        Yang        MM-DD-YY\n",
    "March 3rd, 2019   Sophia       Reilly      Month D, YYYY\n",
    "\n",
    "# Datetime formatting\n",
    "datetime is useful for representing dates\n",
    "Date                datetime format\n",
    "25-12-2019          %d-%m-%Y\n",
    "December 25th 2019  %c\n",
    "12-25-2019          %m-%d-%Y\n",
    "\n",
    "• Can recognize most formats automatically\n",
    "• Sometimes fails with erroneous or\n",
    "• unrecognizable formats\n",
    "pandas.to_datetime()\n",
    "\n",
    "birthdays['Birthday'] = pd.to_datetime(birrthdays['Birthday'], infer_datetime_format = True, errors='coerce') #Attempt to infer format from each date, return NA for rows where conversion failed\n",
    "birthdays['Birthday'] = birthdays['Birthday'].dt.strftime('%d-%m-%y')\n",
    "\n",
    "Treating ambiguous date data\n",
    "Is 2019-03-08 in August or March?\n",
    "• Convert to NA and treat accordingly\n",
    "• Infer format by understanding data source\n",
    "• Infer format by understanding previous and subsequent data in DataFrame\n",
    "\n",
    "# Cross field validation\n",
    "flight_number     economy_class    business_class    first_class    total_passengers\n",
    "DL140             100           +  60             +  40           = 200\n",
    "BA248             130           +  100            +  70           = 300  # verify if economy_class+business_class+first_class = total_passengers\n",
    "\n",
    "# The use of multiple fields in a dataset to sanity check data integrity\n",
    "sum_classes = flights[['economy_class','business_class','first_class']].sum(axis=1)\n",
    "passenger_equ = sum_classes == flights['total_passengers']\n",
    "\n",
    "# find and filter out rows with inconsistent passenger totals\n",
    "inconsistent_pass = flights[~passenger_equ]\n",
    "consistent_pass = flights[passenger_equ]\n",
    "\n",
    "# ex 2\n",
    "user_id Age Birthday\n",
    "32985   22  1998-03-02\n",
    "94387   27  1993-12-04\n",
    "34236   42  1978-11-24\n",
    "12551   31  1989-01-03\n",
    "55212   18  2002-07-02     #verify if current_year - birthyear = Age\n",
    " \n",
    "import pandas as pd \n",
    "import datetime as dt\n",
    "\n",
    "# Convert to datetime and get today's date\n",
    "users['Birthday'] = pd.to_datetime(users['Birthday'])\n",
    "today = dt.date.today()\n",
    "# For each row in the Birthday column, calculate year difference age_manual = today.year - users['Birthday'].dt.year\n",
    "# Convert to datetime and get today's date\n",
    "users['Birthday'] = pd.to_datetime(users['Birthday'])\n",
    "today = dt.date.today()\n",
    "# For each row in the Birthday column, calculate year difference\n",
    "age_manual = today.year - users['Birthday'].dt.year\n",
    "# Find instances where ages match\n",
    "age_equ = age_manual == users['Age']\n",
    "# Find and filter out rows with inconsistent age\n",
    "inconsistent_age = users [~age_equ]\n",
    "consistent_age = users [age_equ]\n",
    "\n",
    "# What to do when we catch inconsistencies\n",
    "Dropping Data\n",
    "Set to missing and impute\n",
    "Apply rules from domain knowledge\n",
    "\n",
    "\n",
    "# What is missing data  (can be represented as NA, nan, 0, ., ...), Occurs when no data value is stored for a variable in an observation, Caused by technical error or human error\n",
    "# Return missing values \n",
    "airquality.isna()\n",
    "     Date   Temperature  C02\n",
    "2119 False  False        False\n",
    "2451 False  False        True\n",
    "\n",
    "# Get summary of missingness \n",
    "airquality.isna().sum()\n",
    "\n",
    "Date           0\n",
    "Temperature    0\n",
    "C02            366\n",
    "dtype: int64\n",
    "    \n",
    "# Missingno (Useful package for visualizing and understanding missing data)\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualize missingness\n",
    "msno.matrix(airquality)\n",
    "plt.show()\n",
    "\n",
    "# Isolate missing and complete values aside\n",
    "missing = airquality [airquality['C02'].isna()] \n",
    "complete = airquality [~airquality ['C02'].isna()]\n",
    "\n",
    "# Describe complete DataFramee complete.describe()\n",
    "      Temperature   C02\n",
    "count 8991.000000   8991.000000\n",
    "mean    18.317829      1.739584\n",
    "\n",
    "# Describe missing DataFramee missing.describe()\n",
    "      Temperature   CO2\n",
    "count 366.000000    0.0\n",
    "mean  -39.655738    NaN\n",
    "\n",
    "# Missingness types\n",
    "Missing Completely at Random (MCAR)\n",
    "No systematic relationship between missing data and other values\n",
    "Data entry errors when inputting data\n",
    "\n",
    "Missing at Random (MAR)\n",
    "Systematic relationship between missing data and other observed values\n",
    "Missing ozone data for high temperatures\n",
    "\n",
    "Missing Not at Random (MNAR)\n",
    "Systematic relationship between missing data and unobserved values\n",
    "Missing temperature values for high temperatures\n",
    "\n",
    "# How to deal with missing data?\n",
    "Simple approaches:\n",
    "1. Drop missing data\n",
    "2. Impute with statistical measures (mean, median, mode..)\n",
    "More complex approaches:\n",
    "1. Imputing using an algorithmic approach\n",
    "2. Impute with machine learning models\n",
    "\n",
    "# drop missing values\n",
    "airquality_dropped = airquality.dropna(subset = ['CO2']) # drops all records that where  co2 is nan\n",
    "\n",
    "# Replacing with statistical measures\n",
    "co2_mean = airquality['CO2'].mean()\n",
    "airquality_imputed = airquality.fillna({'CO2': co2_mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47be627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record Linkage\n",
    "# Minimum edit distance (Comparing the how similar is one string to another)\n",
    "Least possible amount of steps needed to transition from one string to another #ex- REEDING to READING, Here the  minimum edit distance is 1. | ex2- INTENTION to EXECUTION, in this case the minimum edit distance is 5\n",
    "\n",
    "+ Insertion\n",
    "- Deletion\n",
    "* Substitution\n",
    "➡ Transposition\n",
    "\n",
    "Minimum edit distance algorithms\n",
    "Algorithm              Operations\n",
    "Damerau-Levenshtein    insertion, substitution, deletion, transposition\n",
    "Levenshtein            insertion, substitution, deletion\n",
    "Hamming                substitution only\n",
    "Jaro distance          transposition only\n",
    "...\n",
    "Possible packages: thefuzz\n",
    "    \n",
    "# simple string comparision\n",
    "from thefuzz import fuzz\n",
    "# compare reeding vs reading\n",
    "fuzz.wratio('Reeding','Reading') # prints 86 where 0 will be less similar and 100 being the complete match\n",
    "\n",
    "# Partial strings and different orderings\n",
    "# Partial string comparision\n",
    "fuzz.WRatio('Houston Rockets', 'Rockets') # prints 90\n",
    "\n",
    "# Partial string comparision with different order\n",
    "fuzz.WRatio('Houston Rockets vs Los Angeles Lakers', 'Lakers vs Rockets') # prints 86\n",
    "\n",
    "# Comparisiion with arrays\n",
    "# Import process\n",
    "from thefuzz import process\n",
    "\n",
    "# Define a string and array of possible matches\n",
    "string = \"Houston Rockets vs Los Angeles Lakers\"\n",
    "choices = pd.series(['Rockets vs Lakers', 'Lakers vs Rockets', 'Houston vs Los Angeles', 'Heat vs Bulls'])\n",
    "process.extract(string, choices, limit=2) # prints [('Rockets vs Lakers', 86, 0), ('Lakers vs Rockets', 86, 1)]\n",
    "\n",
    "# Collapsing categories with string similarity\n",
    "Chapter 2\n",
    "Use .replace() to collapse \"eur\" into \"Europe\"\n",
    "What if there are too many variations?\n",
    "\"EU\", \"eur\", \"Europ\", \"Europa\", \"Erope\", \"Evropa\" .\n",
    "\n",
    "# Collapsing all of the state\n",
    "# For each correct category\n",
    "for state in categories['state']:\n",
    "    #Find potential matches in states with typos\n",
    "    matches = process.extract(state, survey['state'], limit = survey.shape[0])\n",
    "    #for each potential match match\n",
    "    for potential_match[1] >= 80:\n",
    "        if potential_match[1] >= 80:\n",
    "            #Replace typo with correct category\n",
    "            survey.loc[survey['state'] == potential_match[0], 'state'] = state\n",
    "            \n",
    "            \n",
    "# Record linkage\n",
    "Data A\n",
    "        Generate pairs -> Compare pairs -> Score pairs -> Link data\n",
    "Data B\n",
    "\n",
    "# Generating pairs\n",
    "import recordLinkage\n",
    "\n",
    "# Create indexing object\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Generate pairs blocked on state\n",
    "indexer.block('state')\n",
    "pairs = indexer.index(census_A, census_B)\n",
    "print(pairs) # prints MultiIndex(levels=[['rec-1007-org', 'rec-1016-org', 'rec-1054-org', 'rec-1066-org','rec-1070-org', 'rec-1075-org', 'rec-1080-org',15, 19, 57, 37, 70, 94]], names=['rec_id_1', 'rec_id_2'])\n",
    "\n",
    "# Comparing the dataframes\n",
    "# Generate the pairs\n",
    "pairs = indexer.index(census_A, census_B)\n",
    "\n",
    "# Create a compare object\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches for pairs of date_of_birth and state\n",
    "compare_cl.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "compare_cl.exact('state', 'state', label='state')\n",
    "\n",
    "# Find similar matches for pairs of surname and address_1 using string siimilarity\n",
    "compare_cl.string('surname', 'surname', threshold=0.85, label='surname')\n",
    "compare_cl.string('address_1'. 'address_1', threshold=0.85, label='address_1')\n",
    "\n",
    "# Find matching pairs\n",
    "potential_matches = compare_cl.compute(pairs, census_A, census_B)\n",
    "print(potential_matches)\n",
    "# prints below\n",
    "rec_id_1        rec_id_2         date_of_birth  state surname address_1\n",
    "rec-1070-org    rec-561-dup-0                0              1       0.0\n",
    "                rec-2642-dup-0               0              1       0.0\n",
    "                rec-608-dup-0                0              1       0.0\n",
    "...\n",
    "rec-1631-org    rec-4070-dup-0               0              1       0.0\n",
    "                rec-4862-dup-0               0              1       0.0\n",
    "                rec-629-dup-0                0              1       0.0\n",
    "\n",
    "# Finding the only pairs we want\n",
    "potential_matches[potential_matches.sum(axis=1) => 2]\n",
    "# prints below\n",
    "rec_id_1       rec_id_2         date_of_birth state surname address_1\n",
    "rec-4878-org   rec-4878-dup-0               1     1     1.0       0.0\n",
    "rec-417-org    rec-2867-dup-0               0     1     0.0       1.0\n",
    "rec-3964-org   rec-394-dup-0                0     1     1.0       0.0\n",
    "rec-1373-org   rec-4051-dup-0               0     1     1.0       0.0\n",
    "               rec-802-dup-0                0     1     1.0       0.0\n",
    "\n",
    "# Get the indices\n",
    "matches.index # prints MultiIndex(levels=[['rec-1007-org', 'rec-1016-org', 'rec-1054-org', 'rec-1066-org','rec-1070-org', 'rec-1075-org', 'rec-1080-org', 'rec-110-org',\n",
    "\n",
    "# Get he indices from census_b only\n",
    "duplicate_rows = matches.index.get_level_values(1)\n",
    "print(census_B_index) # prints Index(['rec-2404-dup-0', 'rec-4178-dup-0', 'rec-1054-dup-0', 'rec-4663-dup-0', 'rec-485-dup-0', 'rec-2950-dup-0', 'rec-1234-dup-0','rec-299-dup-0'])\n",
    "\n",
    "# Finding duplicates in census_b\n",
    "census_B_duplicates = census_B[census_B.index.isin(duplicate_rows)]\n",
    "\n",
    "# Finding new rows in census_B\n",
    "census_B_new = census_B[~census_B.index.isin(duplicate_rows)]\n",
    "\n",
    "# Link the dataframe\n",
    "full_census = census_A.append(census_B_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
